{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5ea915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pyspark.sql.types import IntegerType\n",
    "from functools import reduce\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import DataFrame,SparkSession\n",
    "from pyspark.sql.functions import sum\n",
    "#Intializing SparkSession and configuration for spark.config can also set here \n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"test\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a810ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that is created to to read the hdfs file using SparkSession\n",
    "def hdfs_file_read(file):\n",
    "    rdd = spark.read.csv(file, header = True)\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb9b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function performs dataset computation and return dataframe for normalWeek and lockdownWeek  \n",
    "def get_Dataframe(x):\n",
    "    #This lines read the all names the file in hdfs folder and make it a single name with space seperated\n",
    "    p = subprocess.Popen(x,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n",
    "    res = list()\n",
    "    #then the line send to this for loop to run line by line files this has 7 data for normal week and 7 data for lockdownweek\n",
    "        #hdfs://localhost:9000/user/akash/trafficCount/aggre/data1.csv\n",
    "        #hdfs://localhost:9000/user/akash/trafficCount/aggre/data2.csv\n",
    "        #hdfs://localhost:9000/user/akash/trafficCount/aggre/Ldata1.csv\n",
    "        #hdfs://localhost:9000/user/akash/trafficCount/aggre/Ldata1.csv\n",
    "    for line in p.stdout.readlines():\n",
    "        file = line.decode().strip()\n",
    "        rt = hdfs_file_read(file)\n",
    "        rt= rt.withColumn(\"VehicleCount\", rt[\"VehicleCount\"].cast(IntegerType()))\n",
    "        dff1= rt.groupBy(\"class\").sum(\"VehicleCount\") #total count is groupby vehicle class\n",
    "        dff=dff1.withColumnRenamed(\"sum(VehicleCount)\", \"TotalCount\")\n",
    "        res.append(dff)\n",
    "\n",
    "    union_df = reduce(DataFrame.unionAll, res)\n",
    "    union_df=union_df.groupBy(\"class\").avg(\"TotalCount\").sort('class')\n",
    "    return union_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156b17c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|class|   avg(TotalCount)|\n",
      "+-----+------------------+\n",
      "|    0| 551.1428571428571|\n",
      "|    1|           28564.0|\n",
      "|    2| 6314142.714285715|\n",
      "|    3| 814012.5714285715|\n",
      "|    4|57620.142857142855|\n",
      "|    5|175725.85714285713|\n",
      "|    6|304124.71428571426|\n",
      "|    7| 40229.57142857143|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|class|   avg(TotalCount)|\n",
      "+-----+------------------+\n",
      "|    0|204.57142857142858|\n",
      "|    1| 9185.142857142857|\n",
      "|    2|1463737.2857142857|\n",
      "|    3|317359.28571428574|\n",
      "|    4| 19941.85714285714|\n",
      "|    5|           91562.0|\n",
      "|    6|225943.14285714287|\n",
      "|    7|14435.857142857143|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1=\"hdfs dfs -ls hdfs://localhost:9000/user/akash/trafficCount/aggre| awk '{print $8}' | awk 'NR!=1' \"\n",
    "w2=\"hdfs dfs -ls hdfs://localhost:9000/user/akash/trafficCount/lockdownweek| awk '{print $8}' | awk 'NR!=1' \"\n",
    "L=[w1,w2]\n",
    "for i in range(0,2):\n",
    "        j=str(i)\n",
    "        globals()[f\"week{j}\"] =  get_Dataframe(L[i])       \n",
    "#0----NULL\n",
    "#1---M_BIKE\n",
    "#2---car\n",
    "#3---LGV\n",
    "#4---BUS\n",
    "#5---HGV_RIG\n",
    "#6---HGV_ART\n",
    "#7---CARAVAN\n",
    "\n",
    "week0.show()#Normalweek \n",
    "week1.show()#lockdownweek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
